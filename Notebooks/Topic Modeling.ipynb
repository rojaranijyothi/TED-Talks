{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to try two algorithms LDA(Latent Dirichlet Allocation) and NMF(Non-negative Matrix Factorization).\n",
    "\n",
    "- LDA is based on probabilistic graphical modeling while NMF relies on linear algebra. Both algorithms take as input a bag of words matrix (i.e., each document represented as a row, with each columns containing the count of words in the corpus). The aim of each algorithm is then to produce 2 smaller matrices, a document to topic matrix and a word to topic matrix that when multiplied together reproduce the bag of words matrix with the lowest error.\n",
    "\n",
    "- Both NMF and LDA are not able to automatically determine the number of topics and this must be specified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import collections\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import wordcloud\n",
    "\n",
    "## for text processing\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "## for ner\n",
    "import spacy\n",
    "\n",
    "## for vectorizer\n",
    "from sklearn import feature_extraction, manifold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>speaker_occupation</th>\n",
       "      <th>transcript</th>\n",
       "      <th>duration</th>\n",
       "      <th>film_date</th>\n",
       "      <th>published_date</th>\n",
       "      <th>languages</th>\n",
       "      <th>...</th>\n",
       "      <th>ingenious</th>\n",
       "      <th>courageous</th>\n",
       "      <th>longwinded</th>\n",
       "      <th>informative</th>\n",
       "      <th>fascinating</th>\n",
       "      <th>unconvincing</th>\n",
       "      <th>persuasive</th>\n",
       "      <th>ok</th>\n",
       "      <th>obnoxious</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ken Robinson: Do schools kill creativity?</td>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>['Ken Robinson']</td>\n",
       "      <td>['Author', 'educator']</td>\n",
       "      <td>Good morning. How are you?(Laughter)It's been ...</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>2006-02-24</td>\n",
       "      <td>2006-06-26</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>6073</td>\n",
       "      <td>3253</td>\n",
       "      <td>387</td>\n",
       "      <td>7346</td>\n",
       "      <td>10581</td>\n",
       "      <td>300</td>\n",
       "      <td>10704</td>\n",
       "      <td>1174</td>\n",
       "      <td>209</td>\n",
       "      <td>Inspiring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Al Gore: Averting the climate crisis</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>['Al Gore']</td>\n",
       "      <td>['Climate advocate']</td>\n",
       "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
       "      <td>16.283333</td>\n",
       "      <td>2006-02-24</td>\n",
       "      <td>2006-06-26</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>139</td>\n",
       "      <td>113</td>\n",
       "      <td>443</td>\n",
       "      <td>132</td>\n",
       "      <td>258</td>\n",
       "      <td>268</td>\n",
       "      <td>203</td>\n",
       "      <td>131</td>\n",
       "      <td>Funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Pogue: Simplicity sells</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>New York Times columnist David Pogue takes aim...</td>\n",
       "      <td>['David Pogue']</td>\n",
       "      <td>['Technology columnist']</td>\n",
       "      <td>(Music: \"The Sound of Silence,\" Simon &amp; Garfun...</td>\n",
       "      <td>21.433333</td>\n",
       "      <td>2006-02-23</td>\n",
       "      <td>2006-06-26</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>183</td>\n",
       "      <td>45</td>\n",
       "      <td>78</td>\n",
       "      <td>395</td>\n",
       "      <td>166</td>\n",
       "      <td>104</td>\n",
       "      <td>230</td>\n",
       "      <td>146</td>\n",
       "      <td>142</td>\n",
       "      <td>Funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Majora Carter: Greening the ghetto</td>\n",
       "      <td>Greening the ghetto</td>\n",
       "      <td>In an emotionally charged talk, MacArthur-winn...</td>\n",
       "      <td>['Majora Carter']</td>\n",
       "      <td>['Activist for environmental justice']</td>\n",
       "      <td>If you're here today — and I'm very happy that...</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>2006-02-25</td>\n",
       "      <td>2006-06-26</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>760</td>\n",
       "      <td>53</td>\n",
       "      <td>380</td>\n",
       "      <td>132</td>\n",
       "      <td>36</td>\n",
       "      <td>460</td>\n",
       "      <td>85</td>\n",
       "      <td>35</td>\n",
       "      <td>Inspiring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hans Rosling: The best stats you've ever seen</td>\n",
       "      <td>The best stats you've ever seen</td>\n",
       "      <td>You've never seen data presented like this. Wi...</td>\n",
       "      <td>['Hans Rosling']</td>\n",
       "      <td>['Global health expert', ' data visionary']</td>\n",
       "      <td>About 10 years ago, I took on the task to teac...</td>\n",
       "      <td>19.833333</td>\n",
       "      <td>2006-02-21</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>3202</td>\n",
       "      <td>318</td>\n",
       "      <td>110</td>\n",
       "      <td>5433</td>\n",
       "      <td>4606</td>\n",
       "      <td>67</td>\n",
       "      <td>2542</td>\n",
       "      <td>248</td>\n",
       "      <td>61</td>\n",
       "      <td>Informative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            name  \\\n",
       "0      Ken Robinson: Do schools kill creativity?   \n",
       "1           Al Gore: Averting the climate crisis   \n",
       "2                  David Pogue: Simplicity sells   \n",
       "3             Majora Carter: Greening the ghetto   \n",
       "4  Hans Rosling: The best stats you've ever seen   \n",
       "\n",
       "                             title  \\\n",
       "0      Do schools kill creativity?   \n",
       "1      Averting the climate crisis   \n",
       "2                 Simplicity sells   \n",
       "3              Greening the ghetto   \n",
       "4  The best stats you've ever seen   \n",
       "\n",
       "                                         description       main_speaker  \\\n",
       "0  Sir Ken Robinson makes an entertaining and pro...   ['Ken Robinson']   \n",
       "1  With the same humor and humanity he exuded in ...        ['Al Gore']   \n",
       "2  New York Times columnist David Pogue takes aim...    ['David Pogue']   \n",
       "3  In an emotionally charged talk, MacArthur-winn...  ['Majora Carter']   \n",
       "4  You've never seen data presented like this. Wi...   ['Hans Rosling']   \n",
       "\n",
       "                            speaker_occupation  \\\n",
       "0                       ['Author', 'educator']   \n",
       "1                         ['Climate advocate']   \n",
       "2                     ['Technology columnist']   \n",
       "3       ['Activist for environmental justice']   \n",
       "4  ['Global health expert', ' data visionary']   \n",
       "\n",
       "                                          transcript   duration   film_date  \\\n",
       "0  Good morning. How are you?(Laughter)It's been ...  19.400000  2006-02-24   \n",
       "1  Thank you so much, Chris. And it's truly a gre...  16.283333  2006-02-24   \n",
       "2  (Music: \"The Sound of Silence,\" Simon & Garfun...  21.433333  2006-02-23   \n",
       "3  If you're here today — and I'm very happy that...  18.600000  2006-02-25   \n",
       "4  About 10 years ago, I took on the task to teac...  19.833333  2006-02-21   \n",
       "\n",
       "  published_date  languages  ...  ingenious courageous  longwinded  \\\n",
       "0     2006-06-26         60  ...       6073       3253         387   \n",
       "1     2006-06-26         43  ...         56        139         113   \n",
       "2     2006-06-26         26  ...        183         45          78   \n",
       "3     2006-06-26         35  ...        105        760          53   \n",
       "4     2006-06-27         48  ...       3202        318         110   \n",
       "\n",
       "  informative  fascinating unconvincing persuasive    ok  obnoxious  \\\n",
       "0        7346        10581          300      10704  1174        209   \n",
       "1         443          132          258        268   203        131   \n",
       "2         395          166          104        230   146        142   \n",
       "3         380          132           36        460    85         35   \n",
       "4        5433         4606           67       2542   248         61   \n",
       "\n",
       "        rating  \n",
       "0    Inspiring  \n",
       "1        Funny  \n",
       "2        Funny  \n",
       "3    Inspiring  \n",
       "4  Informative  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the preprocessed data\n",
    "ted_talks = pd.read_csv(\"/Users/HOME/Desktop/Springboard/TED-Talks/Data/preprocessed_ted.csv\",index_col = 0)\n",
    "ted_talks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_talks = ted_talks[~(ted_talks['clean_transc'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_talks = ted_talks.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=2455, step=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_talks.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "Topic modeling is a type of statistical modeling for discovering the abstract “topics” that occur in a collection of documents. Latent Dirichlet Allocation (LDA) is an example of topic model and is used to classify text in a document to a particular topic. It builds a topic per document model and words per topic model, modeled as Dirichlet distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "['technology', 'like', 'want', 'come', 'know', 'thing', 'people', 'way', 'time', 'think']\n",
      "Topic 1:\n",
      "['da', 'humor', 'ha', 'da da', 'feminist', 'sensitive', 'thank thank', 'spread', 'approve', 'gray']\n",
      "Topic 2:\n",
      "['people', 'think', 'human', 'way', 'like', 'thing', 'right', 'idea', 'question', 'world']\n",
      "Topic 3:\n",
      "['black', 'community', 'white', 'race', 'american', 'african', 'america', 'man', 'drug', 'color']\n",
      "Topic 4:\n",
      "['life', 'know', 'people', 'come', 'story', 'time', 'like', 'feel', 'day', 'tell']\n",
      "Topic 5:\n",
      "['crispr', 'technology', 'drown', 'broken', 'excitement', 'fee', 'pause', 'venture', 'delight', 'spark']\n",
      "Topic 6:\n",
      "['jihad', 'mid', 'like use', 'optimism', 'deposit', 'relax', 'optimistic', 'bin', 'question question', 'lot different']\n",
      "Topic 7:\n",
      "['city', 'use', 'design', 'new', 'build', 'like', 'work', 'create', 'building', 'project']\n",
      "Topic 8:\n",
      "['like', 'robot', 'look', 'time', 'use', 'light', 'fly', 'come', 'air', 'think']\n",
      "Topic 9:\n",
      "['earth', 'planet', 'universe', 'like', 'life', 'look', 'space', 'time', 'science', 'year']\n",
      "Topic 10:\n",
      "['word', 'language', 'book', 'english', 'use', 'dictionary', 'meaning', 'editor', 'crow', 'shape']\n",
      "Topic 11:\n",
      "['brain', 'cell', 'cancer', 'patient', 'body', 'disease', 'human', 'gene', 'use', 'actually']\n",
      "Topic 12:\n",
      "['message', 'user', 'twitter', 'tweet', 'real time', 'update', 'reply', 'family friend', 'script', 'pharmaceutical']\n",
      "Topic 13:\n",
      "['play', 'game', 'sound', 'music', 'like', 'video', 'hear', 'right', 'let', 'song']\n",
      "Topic 14:\n",
      "['people', 'work', 'money', 'company', 'need', 'year', 'school', 'dollar', 'business', 'come']\n",
      "Topic 15:\n",
      "['thing', 'think', 'know', 'like', 'people', 'want', 'look', 'actually', 'right', 'little']\n",
      "Topic 16:\n",
      "['people', 'country', 'war', 'world', 'government', 'right', 'political', 'power', 'law', 'state']\n",
      "Topic 17:\n",
      "['woman', 'child', 'man', 'girl', 'baby', 'boy', 'young', 'sex', 'mother', 'family']\n",
      "Topic 18:\n",
      "['year', 'people', 'world', 'percent', 'health', 'country', 'need', 'problem', 'change', 'energy']\n",
      "Topic 19:\n",
      "['water', 'year', 'food', 'like', 'animal', 'plant', 'find', 'world', 'ocean', 'know']\n"
     ]
    }
   ],
   "source": [
    "#LDA with number of topics set to 20\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "def build_lda(data, num_of_topic=20):\n",
    "    vec = CountVectorizer(strip_accents = 'ascii',stop_words = STOP_WORDS,ngram_range=(1,2),max_features=5000)\n",
    "    transformed_data = vec.fit_transform(data)\n",
    "    feature_names = vec.get_feature_names()\n",
    "\n",
    "    lda = LatentDirichletAllocation(\n",
    "        n_components=num_of_topic, max_iter=100, \n",
    "        learning_method='online', random_state=0)\n",
    "    lda.fit(transformed_data)\n",
    "\n",
    "    return lda, vec, feature_names\n",
    "\n",
    "def display_word_distribution(model, feature_names, n_word):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        words = []\n",
    "        for i in topic.argsort()[:-n_word - 1:-1]:\n",
    "            words.append(feature_names[i])\n",
    "        print(words)\n",
    "\n",
    "lda_model, vec, feature_names = build_lda(ted_talks['clean_transc'])\n",
    "display_word_distribution(\n",
    "    model=lda_model, feature_names=feature_names, \n",
    "    n_word=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA with number of topics set to 20 with different parameters\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "def build_lda(data, num_of_topic=20):\n",
    "  \n",
    "    vec = CountVectorizer(strip_accents = 'ascii',stop_words = STOP_WORDS)\n",
    "\n",
    "    transformed_data = vec.fit_transform(data)\n",
    "    feature_names = vec.get_feature_names()\n",
    "\n",
    "    lda = LatentDirichletAllocation(\n",
    "        n_components=num_of_topic, max_iter=10, \n",
    "        learning_method='online', random_state=0)\n",
    "    lda.fit(transformed_data)\n",
    "\n",
    "    return lda, vec, feature_names\n",
    "\n",
    "\n",
    "\n",
    "lda_model, vec, feature_names = build_lda(ted_talks['clean_transc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "['poem', 'sex', 'sexual', 'man', 'mosul', 'gold', 'orgasm', 'athlete', 'amanda', 'wine']\n",
      "Topic 1:\n",
      "['hacker', 'gang', 'lie', 'loan', 'glamour', 'glamorous', 'hack', 'deception', 'liar', 'criminal']\n",
      "Topic 2:\n",
      "['internet', 'medium', 'twitter', 'african', 'africa', 'online', 'money', 'tweet', 'facebook', 'chinese']\n",
      "Topic 3:\n",
      "['brain', 'cell', 'patient', 'cancer', 'disease', 'body', 'actually', 'human', 'health', 'drug']\n",
      "Topic 4:\n",
      "['fish', 'ocean', 'shark', 'animal', 'sea', 'tag', 'tuna', 'shrimp', 'jellyfish', 'regret']\n",
      "Topic 5:\n",
      "['camino', 'homeno', 'finisterre', 'mccormack', 'seenthe', 'compostela', 'thatand', 'seaand', 'thinkingthat', 'thinkingi']\n",
      "Topic 6:\n",
      "['fonio', 'kedougou', 'heh', 'everglade', 'senghor', 'dogon', 'thresh', 'okra', 'fouta', 'sanoussi']\n",
      "Topic 7:\n",
      "['like', 'think', 'people', 'know', 'thing', 'time', 'want', 'look', 'work', 'way']\n",
      "Topic 8:\n",
      "['hg', 'nr', 'naghma', 'triceratop', 'jirga', 'justness', 'naser', 'manshiyat', 'dracorex', 'torosaurus']\n",
      "Topic 9:\n",
      "['dna', 'quantum', 'autism', 'strand', 'atom', 'fold', 'lauran', 'molecule', 'crispr', 'origami']\n",
      "Topic 10:\n",
      "['silk', 'spider', 'asl', 'yungay', 'spiderwebs', 'dragline', 'widow', 'visicalc', 'scrapper', 'jitney']\n",
      "Topic 11:\n",
      "['dolphin', 'vagina', 'smallpox', 'polio', 'bali', 'detection', 'quad', 'goliath', 'als', 'david']\n",
      "Topic 12:\n",
      "['fbi', 'argument', 'nsa', 'intelligence', 'encryption', 'nonviolent', 'snowden', 'encrypt', 'cyrus', 'ivan']\n",
      "Topic 13:\n",
      "['doaa', 'lester', 'bassem', 'shaman', 'lesterland', 'galois', 'cymatic', 'misfit', 'federalist', 'uncontacted']\n",
      "Topic 14:\n",
      "['people', 'year', 'world', 'country', 'like', 'think', 'woman', 'know', 'need', 'come']\n",
      "Topic 15:\n",
      "['patent', 'mall', 'troll', 'psychopath', 'abed', 'brad', 'raisuddin', 'archie', 'tidy', 'stint']\n",
      "Topic 16:\n",
      "['music', 'orchestra', 'gabby', 'musician', 'emeka', 'rio', 'rating', 'digit', 'walkable', 'choir']\n",
      "Topic 17:\n",
      "['la', 'li', 'janitor', 'thank', 'fgm', 'marry', 'musical', 'melody', 'composer', 'mogadishu']\n",
      "Topic 18:\n",
      "['norden', 'bombsight', 'phthalate', 'nanopatch', 'river', 'cobra', 'mw', 'gout', 'uric', 'todai']\n",
      "Topic 19:\n",
      "['ems', 'decima', 'twentysomething', 'ella', 'catadore', 'carroca', 'littlebit', 'milonga', 'fabrication', 'fab']\n"
     ]
    }
   ],
   "source": [
    "def display_word_distribution(model, feature_names, n_word):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        words = []\n",
    "        for i in topic.argsort()[:-n_word - 1:-1]:\n",
    "            words.append(feature_names[i])\n",
    "        print(words)\n",
    "\n",
    "\n",
    "display_word_distribution(model=lda_model, feature_names=feature_names, n_word=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "['cell', 'actually', 'like', 'think', 'thing', 'look', 'human', 'gene', 'dna', 'use']\n",
      "Topic 1:\n",
      "['life', 'people', 'feel', 'think', 'world', 'human', 'story', 'experience', 'love', 'live']\n",
      "Topic 2:\n",
      "['universe', 'earth', 'planet', 'like', 'space', 'thing', 'science', 'know', 'look', 'time']\n",
      "Topic 3:\n",
      "['know', 'like', 'thing', 'think', 'want', 'people', 'come', 'time', 'year', 'start']\n",
      "Topic 4:\n",
      "['people', 'think', 'thing', 'like', 'right', 'use', 'actually', 'know', 'want', 'way']\n",
      "Topic 5:\n",
      "['use', 'computer', 'technology', 'like', 'robot', 'game', 'machine', 'human', 'thing', 'play']\n",
      "Topic 6:\n",
      "['people', 'work', 'think', 'thing', 'company', 'money', 'like', 'need', 'dollar', 'good']\n",
      "Topic 7:\n",
      "['food', 'plant', 'eat', 'water', 'grow', 'like', 'need', 'farmer', 'feed', 'plastic']\n",
      "Topic 8:\n",
      "['like', 'look', 'think', 'actually', 'way', 'thing', 'work', 'little', 'sound', 'use']\n",
      "Topic 9:\n",
      "['car', 'energy', 'use', 'year', 'power', 'fly', 'air', 'need', 'time', 'oil']\n",
      "Topic 10:\n",
      "['world', 'country', 'year', 'africa', 'global', 'china', 'india', 'people', 'percent', 'united']\n",
      "Topic 11:\n",
      "['woman', 'man', 'people', 'child', 'year', 'family', 'young', 'girl', 'come', 'school']\n",
      "Topic 12:\n",
      "['brain', 'patient', 'cancer', 'health', 'disease', 'drug', 'doctor', 'year', 'care', 'people']\n",
      "Topic 13:\n",
      "['water', 'year', 'animal', 'ocean', 'find', 'like', 'look', 'time', 'know', 'place']\n",
      "Topic 14:\n",
      "['city', 'design', 'people', 'new', 'build', 'building', 'like', 'work', 'place', 'project']\n"
     ]
    }
   ],
   "source": [
    "#LDA with number of topics set to 15\n",
    "def build_lda(data, num_of_topic=15):\n",
    "  \n",
    "    vec = CountVectorizer(strip_accents = 'ascii',stop_words = STOP_WORDS,max_features=2000)\n",
    "\n",
    "    transformed_data = vec.fit_transform(data)\n",
    "    feature_names = vec.get_feature_names()\n",
    "\n",
    "    lda = LatentDirichletAllocation(n_components=num_of_topic, max_iter=100, \n",
    "                                    learning_method='online', random_state=0)\n",
    "    lda.fit(transformed_data)\n",
    "\n",
    "    return lda, vec, feature_names\n",
    "\n",
    "def display_word_distribution(model, feature_names, n_word):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        words = []\n",
    "        for i in topic.argsort()[:-n_word - 1:-1]:\n",
    "            words.append(feature_names[i])\n",
    "        print(words)\n",
    "\n",
    "\n",
    "lda_model, vec, feature_names = build_lda(ted_talks['clean_transc'])\n",
    "display_word_distribution(model=lda_model, feature_names=feature_names, n_word=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Negative Matrix Factorization(NMF)\n",
    "\n",
    "Non-Negative Matrix Factorization is a statistical method to reduce the dimension of the input corpora. It uses factor analysis method to provide comparatively less weightage to the words with less coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  ['war', 'government', 'political', 'democracy', 'violence', 'conflict', 'election', 'police', 'citizen', 'security']\n",
      "1 :  ['patient', 'health', 'doctor', 'disease', 'medical', 'hospital', 'drug', 'medicine', 'surgery', 'treatment']\n",
      "2 :  ['planet', 'earth', 'mars', 'solar', 'energy', 'atmosphere', 'star', 'sun', 'fly', 'ice']\n",
      "3 :  ['business', 'economy', 'economic', 'market', 'growth', 'china', 'global', 'india', 'cost', 'government']\n",
      "4 :  ['datum', 'computer', 'machine', 'internet', 'phone', 'web', 'digital', 'video', 'online', 'algorithm']\n",
      "5 :  ['brain', 'neuron', 'memory', 'cortex', 'disorder', 'behavior', 'animal', 'consciousness', 'signal', 'pattern']\n",
      "6 :  ['robot', 'robotic', 'machine', 'leg', 'intelligence', 'sensor', 'artificial', 'interact', 'video', 'autonomous']\n",
      "7 :  ['universe', 'galaxy', 'particle', 'star', 'theory', 'telescope', 'physics', 'quantum', 'black', 'hole']\n",
      "8 :  ['cell', 'dna', 'gene', 'genome', 'virus', 'stem', 'genetic', 'bacteria', 'molecule', 'tissue']\n",
      "9 :  ['ocean', 'fish', 'animal', 'sea', 'coral', 'whale', 'marine', 'specie', 'underwater', 'deep']\n",
      "10 :  ['student', 'teacher', 'education', 'classroom', 'game', 'class', 'learning', 'math', 'grade', 'college']\n",
      "11 :  ['music', 'song', 'musician', 'instrument', 'musical', 'listen', 'sing', 'piano', 'concert', 'video']\n",
      "12 :  ['car', 'vehicle', 'road', 'mile', 'driver', 'traffic', 'street', 'lane', 'transportation', 'highway']\n",
      "13 :  ['africa', 'african', 'continent', 'hiv', 'aid', 'south', 'nigeria', 'kenya', 'leader', 'poverty']\n",
      "14 :  ['cancer', 'tumor', 'breast', 'drug', 'disease', 'protein', 'blood', 'treatment', 'cell', 'lung']\n",
      "15 :  ['art', 'artist', 'image', 'painting', 'film', 'paint', 'museum', 'object', 'color', 'draw']\n",
      "16 :  ['girl', 'mother', 'boy', 'father', 'parent', 'daughter', 'sex', 'baby', 'god', 'mom']\n",
      "17 :  ['building', 'architecture', 'architect', 'material', 'structure', 'site', 'air', 'neighborhood', 'wall', 'apartment']\n",
      "18 :  ['language', 'english', 'chinese', 'translate', 'sentence', 'speaker', 'meaning', 'china', 'speech', 'spanish']\n",
      "19 :  ['plant', 'food', 'forest', 'tree', 'eat', 'specie', 'soil', 'farmer', 'animal', 'seed']\n"
     ]
    }
   ],
   "source": [
    "#NMF with number of topics set to 20\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "vectorizer = TfidfVectorizer(strip_accents = 'ascii',stop_words = STOP_WORDS,max_df = 0.25, min_df = 0.02)\n",
    "vectors = vectorizer.fit_transform(ted_talks['clean_transc'])\n",
    "\n",
    "nmf = NMF(n_components=20,random_state=0)\n",
    "\n",
    "\n",
    "topics = nmf.fit_transform(vectors)\n",
    "top_word = 10\n",
    "topic_word, word_weight = {}, {}\n",
    "for tid, t in enumerate(nmf.components_):\n",
    "    topic_word[tid] = [vectorizer.get_feature_names()[i] for i in t.argsort()[:-top_word - 1:-1]]\n",
    "    word_weight[tid] = t[t.argsort()[:-top_word - 1:-1]]\n",
    "\n",
    "for key, val in topic_word.items():\n",
    "    print(key, \": \", val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The derived topics from NMF and LDA are displayed above LDA for this TED Talks dataset produces some of the topics with noisy data and are hard to interpret. I’d say the NMF was able to find more meaningful topics in this dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('tfidf', vectorizer),\n",
    "                     ('nmf', nmf)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Topic Weight:  [0.         0.         0.02279914 0.         0.         0.02554309\n",
      " 0.         0.         0.         0.         0.12278385 0.04714222\n",
      " 0.         0.00252673 0.         0.03857361 0.05385094 0.\n",
      " 0.00048741 0.00376381]\n",
      "\n",
      " Relevant topic for the Transcript:  10\n",
      "\n",
      " Transcript:  Good morning. How are you?(Laughter)It's been great, hasn't it? I've been blown away by the whole thing. In fact, I'm leaving.(Laughter)There have been three themes running through the conference which are relevant to what I want to talk about. One is the extraordinary evidence of human creativity in all of the presentations that we've had and in all of the people here. Just the variety of it and the range of it. The second is that it's put us in a place where we have no idea what's going to happen, in terms of the future. No idea how this may play out.I have an interest in education. Actually, what I find is everybody has an interest in education. Don't you? I find this very interesting. If you're at a dinner party, and you say you work in education — Actually, you're not often at dinner parties, frankly.(Laughter)If you work in education, you're not asked.(Laughter)And you're never asked back, curiously. That's strange to me. But if you are, and you say to somebody, you know, they sa\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([('tfidf', vectorizer),\n",
    "                     ('nmf', nmf)])\n",
    "\n",
    "transcript = pipeline.transform([ted_talks['transcript'].iloc[0]])\n",
    "\n",
    "print(\"\\n Topic Weight: \", transcript[0])\n",
    "print(\"\\n Relevant topic for the Transcript: \", np.argmax(transcript[0]))\n",
    "print(\"\\n Transcript: \", ted_talks['transcript'].iloc[0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_talks['topic'] = ted_talks['clean_transc'].apply(lambda x: np.argmax(pipeline.transform([x]))+1)\n",
    "ted_talks['topic_tag'] =  ted_talks['topic'].apply(lambda x: topic_word[x-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>speaker_occupation</th>\n",
       "      <th>transcript</th>\n",
       "      <th>duration</th>\n",
       "      <th>film_date</th>\n",
       "      <th>published_date</th>\n",
       "      <th>languages</th>\n",
       "      <th>...</th>\n",
       "      <th>longwinded</th>\n",
       "      <th>informative</th>\n",
       "      <th>fascinating</th>\n",
       "      <th>unconvincing</th>\n",
       "      <th>persuasive</th>\n",
       "      <th>ok</th>\n",
       "      <th>obnoxious</th>\n",
       "      <th>rating</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ken Robinson: Do schools kill creativity?</td>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>['Ken Robinson']</td>\n",
       "      <td>['Author', 'educator']</td>\n",
       "      <td>Good morning. How are you?(Laughter)It's been ...</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>2006-02-24</td>\n",
       "      <td>2006-06-26</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>387</td>\n",
       "      <td>7346</td>\n",
       "      <td>10581</td>\n",
       "      <td>300</td>\n",
       "      <td>10704</td>\n",
       "      <td>1174</td>\n",
       "      <td>209</td>\n",
       "      <td>Inspiring</td>\n",
       "      <td>11</td>\n",
       "      <td>[student, teacher, education, classroom, game,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Al Gore: Averting the climate crisis</td>\n",
       "      <td>Averting the climate crisis</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>['Al Gore']</td>\n",
       "      <td>['Climate advocate']</td>\n",
       "      <td>Thank you so much, Chris. And it's truly a gre...</td>\n",
       "      <td>16.283333</td>\n",
       "      <td>2006-02-24</td>\n",
       "      <td>2006-06-26</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>113</td>\n",
       "      <td>443</td>\n",
       "      <td>132</td>\n",
       "      <td>258</td>\n",
       "      <td>268</td>\n",
       "      <td>203</td>\n",
       "      <td>131</td>\n",
       "      <td>Funny</td>\n",
       "      <td>4</td>\n",
       "      <td>[business, economy, economic, market, growth, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Pogue: Simplicity sells</td>\n",
       "      <td>Simplicity sells</td>\n",
       "      <td>New York Times columnist David Pogue takes aim...</td>\n",
       "      <td>['David Pogue']</td>\n",
       "      <td>['Technology columnist']</td>\n",
       "      <td>(Music: \"The Sound of Silence,\" Simon &amp; Garfun...</td>\n",
       "      <td>21.433333</td>\n",
       "      <td>2006-02-23</td>\n",
       "      <td>2006-06-26</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>395</td>\n",
       "      <td>166</td>\n",
       "      <td>104</td>\n",
       "      <td>230</td>\n",
       "      <td>146</td>\n",
       "      <td>142</td>\n",
       "      <td>Funny</td>\n",
       "      <td>5</td>\n",
       "      <td>[datum, computer, machine, internet, phone, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Majora Carter: Greening the ghetto</td>\n",
       "      <td>Greening the ghetto</td>\n",
       "      <td>In an emotionally charged talk, MacArthur-winn...</td>\n",
       "      <td>['Majora Carter']</td>\n",
       "      <td>['Activist for environmental justice']</td>\n",
       "      <td>If you're here today — and I'm very happy that...</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>2006-02-25</td>\n",
       "      <td>2006-06-26</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>380</td>\n",
       "      <td>132</td>\n",
       "      <td>36</td>\n",
       "      <td>460</td>\n",
       "      <td>85</td>\n",
       "      <td>35</td>\n",
       "      <td>Inspiring</td>\n",
       "      <td>18</td>\n",
       "      <td>[building, architecture, architect, material, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hans Rosling: The best stats you've ever seen</td>\n",
       "      <td>The best stats you've ever seen</td>\n",
       "      <td>You've never seen data presented like this. Wi...</td>\n",
       "      <td>['Hans Rosling']</td>\n",
       "      <td>['Global health expert', ' data visionary']</td>\n",
       "      <td>About 10 years ago, I took on the task to teac...</td>\n",
       "      <td>19.833333</td>\n",
       "      <td>2006-02-21</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>5433</td>\n",
       "      <td>4606</td>\n",
       "      <td>67</td>\n",
       "      <td>2542</td>\n",
       "      <td>248</td>\n",
       "      <td>61</td>\n",
       "      <td>Informative</td>\n",
       "      <td>14</td>\n",
       "      <td>[africa, african, continent, hiv, aid, south, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            name  \\\n",
       "0      Ken Robinson: Do schools kill creativity?   \n",
       "1           Al Gore: Averting the climate crisis   \n",
       "2                  David Pogue: Simplicity sells   \n",
       "3             Majora Carter: Greening the ghetto   \n",
       "4  Hans Rosling: The best stats you've ever seen   \n",
       "\n",
       "                             title  \\\n",
       "0      Do schools kill creativity?   \n",
       "1      Averting the climate crisis   \n",
       "2                 Simplicity sells   \n",
       "3              Greening the ghetto   \n",
       "4  The best stats you've ever seen   \n",
       "\n",
       "                                         description       main_speaker  \\\n",
       "0  Sir Ken Robinson makes an entertaining and pro...   ['Ken Robinson']   \n",
       "1  With the same humor and humanity he exuded in ...        ['Al Gore']   \n",
       "2  New York Times columnist David Pogue takes aim...    ['David Pogue']   \n",
       "3  In an emotionally charged talk, MacArthur-winn...  ['Majora Carter']   \n",
       "4  You've never seen data presented like this. Wi...   ['Hans Rosling']   \n",
       "\n",
       "                            speaker_occupation  \\\n",
       "0                       ['Author', 'educator']   \n",
       "1                         ['Climate advocate']   \n",
       "2                     ['Technology columnist']   \n",
       "3       ['Activist for environmental justice']   \n",
       "4  ['Global health expert', ' data visionary']   \n",
       "\n",
       "                                          transcript   duration   film_date  \\\n",
       "0  Good morning. How are you?(Laughter)It's been ...  19.400000  2006-02-24   \n",
       "1  Thank you so much, Chris. And it's truly a gre...  16.283333  2006-02-24   \n",
       "2  (Music: \"The Sound of Silence,\" Simon & Garfun...  21.433333  2006-02-23   \n",
       "3  If you're here today — and I'm very happy that...  18.600000  2006-02-25   \n",
       "4  About 10 years ago, I took on the task to teac...  19.833333  2006-02-21   \n",
       "\n",
       "  published_date  languages  ...  longwinded informative  fascinating  \\\n",
       "0     2006-06-26         60  ...         387        7346        10581   \n",
       "1     2006-06-26         43  ...         113         443          132   \n",
       "2     2006-06-26         26  ...          78         395          166   \n",
       "3     2006-06-26         35  ...          53         380          132   \n",
       "4     2006-06-27         48  ...         110        5433         4606   \n",
       "\n",
       "  unconvincing  persuasive    ok obnoxious       rating  topic  \\\n",
       "0          300       10704  1174       209    Inspiring     11   \n",
       "1          258         268   203       131        Funny      4   \n",
       "2          104         230   146       142        Funny      5   \n",
       "3           36         460    85        35    Inspiring     18   \n",
       "4           67        2542   248        61  Informative     14   \n",
       "\n",
       "                                           topic_tag  \n",
       "0  [student, teacher, education, classroom, game,...  \n",
       "1  [business, economy, economic, market, growth, ...  \n",
       "2  [datum, computer, machine, internet, phone, we...  \n",
       "3  [building, architecture, architect, material, ...  \n",
       "4  [africa, african, continent, hiv, aid, south, ...  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_talks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_talks.to_csv(\"/Users/HOME/Desktop/Springboard/TED-Talks/Models/ted_modeling.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic #</th>\n",
       "      <th>topic tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>war-government-political-democracy-violence-co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>patient-health-doctor-disease-medical-hospital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>planet-earth-mars-solar-energy-atmosphere-star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>business-economy-economic-market-growth-china-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>datum-computer-machine-internet-phone-web-digi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic #                                          topic tag\n",
       "0        1  war-government-political-democracy-violence-co...\n",
       "1        2  patient-health-doctor-disease-medical-hospital...\n",
       "2        3  planet-earth-mars-solar-energy-atmosphere-star...\n",
       "3        4  business-economy-economic-market-growth-china-...\n",
       "4        5  datum-computer-machine-internet-phone-web-digi..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ted_topic = pd.DataFrame()\n",
    "ted_topic['topic'] = [x+1 for x in topic_word.keys()]\n",
    "ted_topic['topic_tag'] = ['-'.join(x) for x in topic_word.values()]\n",
    "ted_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted_topic.to_csv(\"/Users/HOME/Desktop/Springboard/TED-Talks/Models/topics_transcript.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
